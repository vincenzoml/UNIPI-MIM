# Auto-converted: 978-3-030-78089-0_12.pdf

(First-pass conversion; manual edits recommended.)

Towards a Spatial Model Checker on
GPU

Laura Bussi1, Vincenzo Ciancia2(B), and Fabio Gadducci1

1 Dipartimento di Informatica, Universit`a di Pisa, Pisa, Italy
laura.bussi@phd.unipi.it,fabio.gadducci@unipi.it
2 Istituto di Scienza e Tecnologie dell’Informazione, CNR, Pisa, Italy
vincenzo.ciancia@isti.cnr.it

Abstract. The tool VoxLogicA merges the state-of-the-art library of
computational imaging algorithms ITK with the combination of declara-
tive speciﬁcation and optimised execution provided by spatial logic model
checking. The analysis of an existing benchmark for segmentation of
brain tumours via a simple logical speciﬁcation reached very high accu-
racy. We introduce a new, GPU-based version of VoxLogicA and present
preliminary results on its implementation, scalability, and applications.

Keywords: Spatial logics · Model checking · GPU computation

1 Introduction and Background

Spatial and Spatio-temporal model checking have gained an increasing interest in
recent years in various application domains, including collective adaptive [11,12]
and networked systems [5], runtime monitoring [4,15,17], modelling of cyber-
physical systems [20] and medical imaging [3,13]. Introduced in [7], VoxLogicA
(Voxel-based Logical Analyser )1 caters for a declarative approach to (medical)
image segmentation, supported by spatial model checking. A spatial logic is
deﬁned, tailored to high-level imaging features, such as regions, contact, texture,
proximity, distance. Spatial operators are mostly derived from the Spatial Logic
of Closure Spaces (SLCS, see Fig. 1). Models of the spatial logic are (pixels
of) images, with atomic propositions given by imaging features (e.g. colour,
intensity), and spatial structure obtained via adjacency of pixels. SLCS features
a modal operator near, denoting adjacency of pixels, and a reachability operator
ρ φ1[φ2], holding at pixel x whenever there is a path from x to a pixel y satisfying
φ1, with all intermediate points, except the extremes, satisfying φ2.

Research partially supported by the MIUR Project PRIN 2017FTXR7S “IT- MaT-
TerS” and by POR FESR Toscana 2014–2020 As. 1 - Az. 1.1.5 – S.A. A1 N. 7165
project STINGRAY. The authors are thankful to: Raﬀaele Perego, Franco Maria Nar-
dini and the HPC-Lab at ISTI-CNR for a powerful GPU used in early development;
Gina Belmonte, Diego Latella, and Mieke Massink, for fruitful discussions. The authors
are listed in alphabetical order, having equally contributed to this work.
1 VoxLogicA: see https://github.com/vincenzoml/VoxLogicA.

c(cid:2) IFIP International Federation for Information Processing 2021
Published by Springer Nature Switzerland AG 2021
K. Peters and T. A. C. Willemse (Eds.): FORTE 2021, LNCS 12719, pp. 188–196, 2021.
https://doi.org/10.1007/978-3-030-78089-0_12

Towards a Spatial Model Checker on GPU

189

Fig. 1. SLCS syntax. Atomic propositions p correspond to image properties (e.g. inten-
sity, colour); boolean operators act pixel-wise; the near operator N denotes pixel adja-
cency (using 8-adjacency: the pixels having a vertex in common with a given one).

The main case study of [7] is brain tumour segmentation for radiotherapy,
using the BraTS 2017 public dataset of medical images [2]. An high-level speciﬁ-
cation for glioblastoma segmentation was proposed and tested using VoxLogicA,
resulting in a procedure that competes in accuracy with state-of-the-art tech-
niques. In [6], also an accurate speciﬁcation for nevus segmentation was pre-
sented. This paper introduces a novel development in the direction of taking
advantage of Graphical Processing Units: high-performance, massively parallel
computational devices. GPU computing diﬀers from the multi-core paradigm
of modern CPUs in many respects: the execution model is Single Instruction
Multiple Data; the number of computation cores is high; the memory model is
highly localised and synchronisation among parallel threads is very expensive.
Each GPU core performs the same operation on diﬀerent coordinates (a single
pixel, in our case). The dimension of the problem (e.g. the size of an image) is
provided to the GPU when the program (kernel ) is launched, yet the number of
threads does not scale with the problem size, being bounded by the number of
computing units in the GPU. Currently, such a number is in the order of thou-
sands, whereas the problem size may include millions of tasks. The problems that
beneﬁt the most of such architecture are the inherently massively parallel ones.
In that case, the main issue is to minimise read/write operations from and to
the GPU memory, and to turn a problem into a highly parallel implementation.
A substantial redesign is thus required to port existing algorithms to GPUs.
VoxLogicA-GPU implements the core logical primitives of VoxLogicA on GPU,
sharing motivation with a recent trend on implementing formal methods on GPU
[8,16,18,21,22]. This paper aims to describe the tool architecture, including
asynchronous execution of logical primitives on GPU and garbage collection,
and to demonstrate a consistent eﬃciency improvement. In doing so, we had
to overcome two major issues: implementing connected component labelling on
GPUs and minimising the number of (computationally expensive) CPU ↔ GPU
memory transfers. Our current results are very encouraging, obtaining a (task-
dependent) speed-up of one or two orders of magnitude.

2 Functional Description and Implementation

VoxLogicA-GPU2 is a global, explicit state model checker, aiming at high eﬃ-
ciency and maximum portability. It is implemented in FSharp, using the NET

2 VoxLogicA-GPU is Free and Open Source software. Its source code is currently avail-

able at https://github.com/vincenzoml/VoxLogicA/tree/experimental-gpu.

190

L. Bussi et al.

Core infrastructure, and the General-Purpose GPU computing library OpenCL3.
The choice of OpenCL is motivated by portability to diﬀerent GPU brands.
VoxLogicA-GPU is a command line tool, accepting as input a text ﬁle describing
the analysis, and a number of input images. The text ﬁle contains a set of logic
formulas and parametrised, non-recursive macro abbreviations. As in [7], the
tool expands macros, identiﬁes the ground formulas (that is, without variables),
and constructs a directed acyclic graph of tasks and dependencies. Such a graph
is equivalent to the syntax tree, but it enjoys maximal sharing: no sub-formula is
ever computed twice. In the CPU version, the tasks run in parallel on the avail-
able CPU cores, yielding a speed-up proportional to the degree of parallelism
of the task graph and to the number of cores. In the GPU version, the tasks
are currently executed asynchronously with respect to the main CPU execution
thread, but sequentially: so-called out-of-order execution is left for future work.
The focus of this ﬁrst release of VoxLogicA-GPU is on the design of a free
and open source GPU-based infrastructure, with proven scalability. Thus, devel-
opment has been narrowed to a core implementation that is powerful enough to
reach the stated objectives, although not as feature-complete as VoxLogicA. In
particular, the implemented primitives are those of SLCS plus basic arithmetics,
and computation is restricted to 2D and integer-valued images. Implementation-
wise, VoxLogicA-GPU is a command-line tool. It takes only one parameter, a text
ﬁle containing the speciﬁcation to be executed, i.e., a sequence of commands.
Five commands are currently implemented: let, load, save, print, import.
The model checking algorithm of VoxLogicA-GPU is shared with VoxLogicA.
After parsing, parametric macros are expanded, while at the same time (to
avoid explosion of the syntax tree) the aforementioned task graph is computed.
A major issue is that each task allocates a memory area proportional to the
size of the input image to store its results, thus garbage collection is required.
The current strategy is a simple reference counting, as the number of reverse
dependencies of each task (i.e. the tasks taking the given one as argument) is
known before execution, and no task is created at run time. This problem is
more relevant to the GPU implementation: as a GPU memory is usually smaller
than a CPU one, and GPU buﬀers are explicitly allocated by the programmer,
large formulas can easily lead to Out of Memory errors at run time. If a refer-
ence counter turns to 0, no more tasks take the given one as an input, and the
pointer referencing the buﬀer can be disposed. As no pointer longer refers that
GPU memory area, this can be reused. A task is an operator of the language
or an output instruction. The semantics of the former is delegated to the GPU
implementation of the VoxLogicA API, deﬁning the core type Value, which is
instantiated as a shorthand for a type called GPUImage. Such type represents
a computation, asynchronously running on a GPU, whose purpose is to ﬁll an
image buﬀer. GPUImage contains a pointer to a buﬀer stored in the GPU, its
imaging features, and an OpenCL event (an handle to the asynchronous compu-
tation). The latter is used to wait for termination before transferring the results

3 FSharp: see https://fsharp.org. NET Core: see https://dotnet.microsoft.com. OpenCL:

see https://www.khronos.org/opencl. ITK: see https://itk.org.

Towards a Spatial Model Checker on GPU

191

to the CPU and to make task dependencies explicit to the GPU for proper
sequencing. Since commands, parameters, and results must be transferred from
the CPU to the GPU and back, keeping pointers to GPU buﬀers minimises this
overhead, allowing for the reuse of partial results. Thus, data is transferred only
at the beginning of the computation and when retrieving results to be saved to
disk. The model checker is responsible for decreasing reference counts after each
task terminates, and for scheduling garbage collection when a reference counter
reaches 0. Each operator is implemented in a small module running on CPU,
whose only purpose is to prepare memory buﬀers and launch one or more ker-
nels (i.e. functions running on GPU). As in VoxLogicA, the reachability operator
ρ φ1[φ2] is implemented using connected components labelling.

2.1 Connected Components Labelling in VoxLogicA-GPU

We designed a simple algorithm for connected component labelling, biased
towards implementation simplicity, although eﬃcient enough for our proto-
type. Similarly to the classic result in [19], the algorithm exploits the pointer
jumping technique4: see Algorithm 1 for the pseudo-code of the kernels (ter-
mination checking is omitted) and Fig. 2 for an example. After initialisation,
mainIteration is iterated. By pointer jumping, it converges in logarithmic time
with respect to the number of pixels N , but it may fail to correctly label con-
nected components with corners in speciﬁc directions (see Fig. 2, Iteration 13).
Then reconnect is called, checking if there are two adjacent pixels with diﬀerent
labels, and changing one of them (deterministically chosen) so that the two labels
now coincide The way reconnect changes the image ensures that mainIteration
will restart and will be enabled to converge again. The termination condition
is reached when reconnect does not change the image, which requires a global
check on its input and output. For checking termination we adopted a reduce-
type operation5: it takes log(N ) iterations, since it divides the image size at each
iteration until a single-pixel image containing a boolean ﬂag is obtained. If the
termination condition is false, the algorithm restarts from mainIteration6. In
most cases, reconnect is called a very small number of times before convergence,
and the total number of iterations is in the order of log(N ) (see [10] for details).

4 Pointer jumping or path doubling is a design technique for parallel algorithms that
operate on pointer structures, such as linked lists and directed graphs. It allows an
algorithm to follow paths with a time complexity that is logarithmic with respect
to the length of the longest path. It does this by “jumping” to the end of the path
computed by neighbors. See https://en.wikipedia.org/wiki/Pointer jumping.

5 See e.g. https://en.wikipedia.org/wiki/MapReduce.
6 Since checking termination takes

log(N )
instead of waiting for
mainIteration to converge, reconnect is called each k iterations (k = 8 in the current
implementation, which experimentally proved to be a reasonable compromise).

iterations,

192

L. Bussi et al.

Algorithm 1: Pseudocode for connected components labelling
1 initialization(start: image of bool, output: image of int × int)
2

// parallel for on GPU

3

4

for (i, j) ∈ Coords do
if start(i,j) then

output(i, j) = (i, j) // null otherwise

5
6 mainIteration(start: image of bool, input, output: image of int × int)
7

// parallel for on GPU

8

9

for (i, j) ∈ Coords do
if start(i,j) then

10

(i(cid:2), j(cid:2)) = input(i, j) // pointer jumping
output(i, j) = maxN eighbour(input, i(cid:2), j(cid:2))
11
12 reconnect(start: image of bool, input, output: image of int × int)
13

// parallel for on GPU

14

15

16

17

18

19

20

for (i, j) ∈ Coords do
if start(i,j) then

(i(cid:2), j(cid:2)) = input(i, j)
(a, b) = maxN eighbour(input, i, j)
(c, d) = input(i(cid:2), j(cid:2))
if (a, b) > (c, d) then

output(i(cid:2), j(cid:2)) = (a, b) // Requires atomic write

3 Preliminary Evaluation

This section illustrates the scalability results obtained in our preliminary tests7.
Experiments have been executed on a machine equipped with an Intel Core
i9-9900K and a NVIDIA RTX 3080 GPU. This is indicative of the attainable
speed-up as both CPU and GPU are current, high-end (workstation-oriented)
devices. It is important to remark that CPU and GPU execution times are sub-
ject to high variability. Indeed, a highly parallel test may run about 8 times
faster on CPU with 16 cores (a current high-end desktop workstation) than a
machine with 2 cores (a current travelling laptop), as witnessed by the law on
theoretical speed-up given by parallel machines [14]. Since the range of current
CPUs is highly variable, so are the execution times in our tests. This fact also
explains the diﬀerent speedup in our tests comparing CPU and GPU on sequen-
tial and parallel tasks (see Fig. 3 and Fig. 4). In the parallel test, all the 16 cores
of the chosen CPU are exploited, thus the CPU is more eﬃcient.

We built two kinds of large formulas for stressing the tool: sequential
(i.e. of shape f (g(. . . (x)))) and “parallel” ones, where the operators are com-
posed in order to maximise parallelism. More precisely, formulas are writ-
ten in order to have many independent sub-formulas (i.e., having shape
f (g(. . . , . . .), h(. . . , . . .))). In the CPU implementation, such sub-formulas can
be computed in parallel, up to the number of available cores. Note again that

7 All the tests we present, and the script to run them, are available in the source code

repository https://github.com/vincenzoml/VoxLogicA/tree/experimental-gpu.

Towards a Spatial Model Checker on GPU

193

Fig. 2. CC-labelling of a 2048 × 2048 pixels image in 24 iterations. Diﬀerent colours
represent diﬀerent labels. Reconnect is called every 8 main iterations. Iteration 13: the
main iterations converged; the image does not change until iteration 16 (reconnect).
Iteration 17: label propagation after reconnect. Iteration 24: termination.

Fig. 3. Execution times for the sequential test.

maximising CPU usage entails a smaller speedup for the GPU. Figure 3 and 4
report execution times for each type of test. Each row reports the number of tasks
to execute (i.e., the number of nodes in the directed acyclic graph described in
Sect. 2), and the obtained speed-up for the two GPU algorithms. In all cases,
VoxLogicA-GPU achieves a relevant speed-up. The CPU version performs better
on very small formulas, due to the overhead needed to set up GPU computation.
The version with garbage collection is much slower than the version without.
This is due to garbage collection being run in the current implementation as
soon as reference counts reach 0, and recall that memory deallocation and real-
location is particularly expensive on GPUs. Obvious improvements are expected
by scheduling garbage collection to be run only when a memory usage threshold
is reached. However, we plan to design a garbage collector which is more speciﬁc
to the execution patterns of a model checker. We also carried out a preliminary
assessment of the brain tumour segmentation case study of [7]. Given the current
restrictions of VoxLogicA-GPU to 2D images and the core logical primitives (see
Sect. 2), it is only possible to use a simpliﬁed dataset and speciﬁcation, obtaining
too small tasks for interesting measurements. We omit the full results (see [10]),
but we note that a mild speed-up was obtained: this is interesting, as the CPU
version uses a state-of-the-art imaging library designed for high eﬃciency.

194

L. Bussi et al.

Fig. 4. Execution times for the parallel test.

4 Conclusions and Future Work

Our preliminary evaluation of spatial model checking on GPU is encouraging:
large formulas beneﬁt most, with signiﬁcant speedups. Connected components
labelling will be a focus for future work: indeed, the topic is very active, and
our simple, proof-of-concept algorithm might well be replaced by state-of-the-art
procedures (see e.g. the recent [1]). The currently attained speed-up can be used,
for instance, for interactive calibration of parameters or for automated parame-
ter optimisation, e.g. using gradient descent algorithms. However, given the peak
performance of recent GPUs, our results are just the tip of the iceberg of what
can be achieved. Future work will concentrate on fully exploiting more powerful
GPUs, using out-of-order execution to permit the execution of more indepen-
dent tasks at the same time, and taking into account GPU-speciﬁc architectural
features (memory banking, number of channels, etc.). Making VoxLogicA-GPU
feature-complete with respect to VoxLogicA is also a goal. In this respect, we
remark that although in this work we decided to go through the “GPU-only”
route, future developments will also consider a hybrid execution mode with some
operations executed on the CPU, so that existing primitives in VoxLogicA can
be run in parallel with those that have a GPU implementation. Usability of
VoxLogicA-GPU would be greatly enhanced by a user interface. However, under-
standing modal logical formulas is generally considered a diﬃcult task, and cog-
nitive/human aspects may become predominant with respect to technological
concerns. Formal methods could be used to mitigate such concerns (see e.g. [9]).

Towards a Spatial Model Checker on GPU

195

References

1. Allegretti, S., Bolelli, F., Grana, C.: Optimized block-based algorithms to label
connected components on GPUs. IEEE Trans. Parallel Distrib. Syst. 31(2), 423–
438 (2020)

2. Bakas, S., et al.: Advancing the cancer genome atlas glioma MRI collections with

expert segmentation labels and radiomic features. Sci. Data 4, 1–13 (2017)

3. Banci Buonamici, F., Belmonte, G., Ciancia, V., Latella, D., Massink, M.: Spatial
logics and model checking for medical imaging. Softw. Tools Technol. Transf. 22(2),
195–217 (2020). https://doi.org/10.1007/s10009-019-00511-9

4. Bartocci, E., Bortolussi, L., Loreti, M., Nenzi, L.: Monitoring mobile and spatially
distributed cyber-physical systems. In: Talpin, J., Derler, P., Schneider, K. (eds.)
MEMOCODE 2017, pp. 146–155. ACM (2017)

5. Bartocci, E., Gol, E., Haghighi, I., Belta, C.: A formal methods approach to pat-
tern recognition and synthesis in reaction diﬀusion networks. IEEE Trans. Control
Netw. Syst. 5(1), 308–320 (2016)

6. Belmonte, G., Broccia, G., Ciancia, V., Latella, D., Massink, M.: Feasibility of
spatial model checking for nevus segmentation. In: Bliudze, S., Semini, L. (eds.)
FORMALISE@ICSE 2021 (2021, to appear)

7. Belmonte, G., Ciancia, V., Latella, D., Massink, M.: VoxLogicA: a spatial model
checker for declarative image analysis. In: Vojnar, T., Zhang, L. (eds.) TACAS
2019. LNCS, vol. 11427, pp. 281–298. Springer, Cham (2019). https://doi.org/10.
1007/978-3-030-17462-0 16

8. Berkovich, S., Bonakdarpour, B., Fischmeister, S.: GPU-based runtime veriﬁcation.

In: IPDPS 2013, pp. 1025–1036. IEEE Computer Society (2013)

9. Broccia, G., Milazzo, P., ¨Olveczky, P.C.: Formal modeling and analysis of safety-
critical human multitasking. Innovations Syst. Softw. Eng. 15(3–4), 169–190
(2019). https://doi.org/10.1007/s11334-019-00333-7

10. Bussi, L., Ciancia, V., Gadducci, F.: A spatial model checker in GPU (extended

version). CoRR abs/2010.07284 (2020)

11. Ciancia, V., Latella, D., Massink, M., Paˇskauskas, R., Vandin, A.: A tool-chain for
statistical spatio-temporal model checking of bike sharing systems. In: Margaria,
T., Steﬀen, B. (eds.) ISoLA 2016. LNCS, vol. 9952, pp. 657–673. Springer, Cham
(2016). https://doi.org/10.1007/978-3-319-47166-2 46

12. Ciancia, V., Gilmore, S., Grilletti, G., Latella, D., Loreti, M., Massink, M.: Spatio-
temporal model checking of vehicular movement in public transport systems. Softw.
Tools Technol. Transf. 20(3), 289–311 (2018). https://doi.org/10.1007/s10009-018-
0483-8

13. Grosu, R., Smolka, S., Corradini, F., Wasilewska, A., Entcheva, E., Bartocci, E.:
Learning and detecting emergent behavior in networks of cardiac myocytes. Com-
mun. ACM 52(3), 97–105 (2009)

14. Gustafson, J.L.: Reevaluating Amdahl’s law. Commun. ACM 31(5), 532–533

(1988)

15. Ma, M., Bartocci, E., Liﬂand, E., Stankovic, J., Feng, L.: SaSTl: spatial aggregation
signal temporal logic for runtime monitoring in smart cities. In: ICCPS 2020, pp.
51–62. IEEE (2020)

16. Neele, T., Wijs, A., Boˇsnaˇcki, D., van de Pol, J.: Partial-order reduction for GPU
model checking. In: Artho, C., Legay, A., Peled, D. (eds.) ATVA 2016. LNCS,
vol. 9938, pp. 357–374. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-
46520-3 23

196

L. Bussi et al.

17. Nenzi, L., Bortolussi, L., Ciancia, V., Loreti, M., Massink, M.: Qualitative and
quantitative monitoring of spatio-temporal properties with SSTL. Log. Methods
Comput. Sci. 14(4), 2:1–2:38 (2018)

18. Osama, M., Wijs, A.: Parallel SAT simpliﬁcation on GPU architectures. In: Vojnar,
T., Zhang, L. (eds.) TACAS 2019. LNCS, vol. 11427, pp. 21–40. Springer, Cham
(2019). https://doi.org/10.1007/978-3-030-17462-0 2

19. Shiloach, Y., Vishkin, U.: An O(logn) parallel connectivity algorithm. J. Algo-

rithms 3(1), 57–67 (1982)

20. Tsigkanos, C., Kehrer, T., Ghezzi, C.: Modeling and veriﬁcation of evolving cyber-
physical spaces. In: Bodden, E., Sch¨afer, W., van Deursen, A., Zisman, A. (eds.)
ESEC/FSE 2017, pp. 38–48. ACM (2017)

21. Wijs, A., Boˇsnaˇcki, D.: Many-core on-the-ﬂy model checking of safety properties
using GPUs. Softw. Tools Technol. Transf. 18(2), 169–185 (2016). https://doi.org/
10.1007/s10009-015-0379-9

22. Wijs, A., Neele, T., Boˇsnaˇcki, D.: GPUexplore 2.0: unleashing GPU explicit-state
model checking. In: Fitzgerald, J., Heitmeyer, C., Gnesi, S., Philippou, A. (eds.)
FM 2016. LNCS, vol. 9995, pp. 694–701. Springer, Cham (2016). https://doi.org/
10.1007/978-3-319-48989-6 42

