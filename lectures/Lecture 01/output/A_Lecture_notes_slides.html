<!DOCTYPE html>
<html lang="en"><head>
<script src="A_Lecture_notes_slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="A_Lecture_notes_slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="A_Lecture_notes_slides_files/libs/quarto-html/popper.min.js"></script>
<script src="A_Lecture_notes_slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="A_Lecture_notes_slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="A_Lecture_notes_slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="A_Lecture_notes_slides_files/libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.29">

  <title>a_lecture_notes_slides</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="A_Lecture_notes_slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="A_Lecture_notes_slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="A_Lecture_notes_slides_files/libs/revealjs/dist/theme/quarto-8a5cdbf101a0845817b98f2425171703.css">
  <link href="A_Lecture_notes_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="A_Lecture_notes_slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="A_Lecture_notes_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="A_Lecture_notes_slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section>
<section id="lecture-1-introduction-to-hybrid-ai-and-formal-methods-in-medical-imaging" class="title-slide slide level1 center">
<h1>Lecture 1: Introduction to Hybrid AI and Formal Methods in Medical Imaging</h1>
<p><strong>Course:</strong> Formal and Hybrid Methods for Medical Imaging<br>
<strong>Date:</strong> September 15, 2025<br>
<strong>Duration:</strong> 2 hours<br>
<strong>Instructor:</strong> Vincenzo</p>
</section>
<section id="learning-objectives" class="slide level2">
<h2>Learning Objectives</h2>
<p>By the end of this lecture, students will be able to: - Understand the concept of hybrid AI and its relevance to medical imaging - Distinguish between symbolic, subsymbolic, and hybrid approaches - Recognize the role of formal methods in medical image analysis - Understand the basic principles of VoxLogica and spatial model checking - Appreciate the ethical considerations in AI-driven medical imaging</p>
</section>
<section id="introduction-the-landscape-of-ai-in-medical-imaging-30-minutes" class="slide level2">
<h2>1. Introduction: The Landscape of AI in Medical Imaging (30 minutes)</h2>
<h3 id="traditional-approaches-vs.-modern-ai">1.1 Traditional Approaches vs.&nbsp;Modern AI</h3>
<p>Medical imaging has evolved from purely manual interpretation to sophisticated automated analysis. Today’s landscape includes:</p>
<p><strong>Traditional Image Processing:</strong> - Rule-based algorithms - Mathematical morphology - Feature extraction based on domain knowledge - Deterministic, interpretable results</p>
<p><strong>Modern Machine Learning:</strong> - Deep neural networks (CNNs, U-Net, nnU-Net) - Data-driven feature learning - High performance on specific tasks - Often “black box” with limited interpretability</p>
<p><strong>The Gap:</strong> - Traditional methods: interpretable but limited in complex scenarios - ML methods: powerful but lack transparency and domain knowledge integration</p>
<h3 id="what-is-hybrid-ai">1.2 What is Hybrid AI?</h3>
<p>Hybrid AI combines the strengths of different AI paradigms:</p>
<pre><code>Hybrid AI = Symbolic AI + Subsymbolic AI + Human Knowledge</code></pre>
<p><strong>Key Characteristics:</strong> - <strong>Complementarity:</strong> Different methods handle different aspects of the problem - <strong>Interpretability:</strong> Formal methods provide explainable reasoning - <strong>Robustness:</strong> Multiple approaches reduce single-point failures - <strong>Domain Integration:</strong> Incorporates medical expertise and constraints</p>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="the-three-pillars-of-ai-in-medical-imaging-45-minutes" class="slide level2">
<h2>2. The Three Pillars of AI in Medical Imaging (45 minutes)</h2>
<h3 id="symbolic-ai-formal-methods">2.1 Symbolic AI (Formal Methods)</h3>
<p><strong>Definition:</strong> AI based on explicit representation of knowledge using symbols and logical rules.</p>
<p><strong>In Medical Imaging:</strong> - Spatial logic for describing anatomical relationships - Rule-based segmentation using geometric constraints - Formal verification of image analysis pipelines</p>
<p><strong>Example:</strong> “A brain lesion is a connected region with intensity &gt; threshold AND distance from ventricles &lt; 5mm”</p>
<h3 id="subsymbolic-ai-machine-learning">2.2 Subsymbolic AI (Machine Learning)</h3>
<p><strong>Definition:</strong> AI that learns patterns from data without explicit symbolic representation.</p>
<p><strong>In Medical Imaging:</strong> - Convolutional Neural Networks for segmentation - Deep learning for classification - Generative models for image synthesis</p>
<p><strong>Example:</strong> A CNN trained on 10,000 brain scans learns to segment tumors without explicit rules.</p>
<h3 id="hybrid-approaches">2.3 Hybrid Approaches</h3>
<p><strong>Definition:</strong> Integration of symbolic and subsymbolic methods to leverage both data-driven learning and domain knowledge.</p>
<p><strong>Strategies:</strong> 1. <strong>Sequential:</strong> ML preprocessing → Formal verification 2. <strong>Parallel:</strong> Multiple methods vote on results 3. <strong>Integrated:</strong> Formal constraints guide ML training 4. <strong>Hierarchical:</strong> Different methods at different scales</p>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="introduction-to-formal-methods-and-model-checking-30-minutes" class="slide level2">
<h2>3. Introduction to Formal Methods and Model Checking (30 minutes)</h2>
<h3 id="what-are-formal-methods">3.1 What are Formal Methods?</h3>
<p><strong>Definition:</strong> Mathematical techniques for specification, development.</p>
<p>Verification of software and hardware systems.</p>
<p><strong>Key Components:</strong> - <strong>Formal specification:</strong> Mathematical description of system behavior - <strong>Formal verification:</strong> Mathematical proof of correctness - <strong>Model checking:</strong> Automated verification of finite-state systems</p>
<h3 id="model-checking-in-medical-imaging">3.2 Model Checking in Medical Imaging</h3>
<p><strong>Traditional Model Checking:</strong> - Verifies software/hardware systems - Checks if system satisfies temporal logic properties - Example: “The system never enters an unsafe state”</p>
<p><strong>Spatial Model Checking:</strong> - Verifies spatial properties of images - Checks if image regions satisfy spatial logic formulas - Example: “All tumor regions are connected and have high intensity”</p>
<h3 id="why-formal-methods-in-medical-imaging">3.3 Why Formal Methods in Medical Imaging?</h3>
<p><strong>Advantages:</strong> - <strong>Precision:</strong> Exact mathematical specification of requirements - <strong>Verification:</strong> Proof that analysis meets specifications - <strong>Interpretability:</strong> Clear reasoning about results - <strong>Reliability:</strong> Reduced errors in critical medical applications</p>
<p><strong>Challenges:</strong> - <strong>Complexity:</strong> Requires mathematical expertise - <strong>Scalability:</strong> May be computationally intensive - <strong>Flexibility:</strong> Less adaptable than learning-based methods</p>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="voxlogica-spatial-model-checking-for-medical-images-45-minutes" class="slide level2">
<h2>4. VoxLogica: Spatial Model Checking for Medical Images (45 minutes)</h2>
<h3 id="what-is-voxlogica">4.1 What is VoxLogica?</h3>
<p><strong>VoxLogica</strong> is a spatial model checker specifically designed for medical image analysis.</p>
<p><strong>Key Features:</strong> - <strong>Spatial Logic:</strong> Describes spatial relationships in images - <strong>3D Support:</strong> Handles volumetric medical data (MRI, CT) - <strong>Declarative:</strong> Specify what to find, not how to find it - <strong>Verification:</strong> Proves properties about image regions</p>
<h3 id="spatial-logic-fundamentals">4.2 Spatial Logic Fundamentals</h3>
<p><strong>Basic Concepts:</strong> - <strong>Atomic Propositions:</strong> Basic properties (e.g., “high intensity”) - <strong>Spatial Operators:</strong> Describe spatial relationships - <strong>Logical Connectives:</strong> AND, OR, NOT, IMPLIES</p>
<p><strong>Spatial Operators:</strong> - <code>near(φ, d)</code>: Points within distance d of regions satisfying φ - <code>surrounded(φ, ψ)</code>: Regions φ completely enclosed by regions ψ - <code>connected(φ)</code>: Connected components satisfying φ</p>
<p><strong>Example Formula:</strong></p>
<pre><code>tumor := intensity &gt; 150 AND connected(true)
edema := near(tumor, 10) AND intensity &gt; 100</code></pre>
<h3 id="voxlogica-in-practice">4.3 VoxLogica in Practice</h3>
<p><strong>Workflow:</strong> 1. <strong>Image Loading:</strong> Import medical images (DICOM, NIfTI) 2. <strong>Property Definition:</strong> Write spatial logic formulas 3. <strong>Model Checking:</strong> Verify properties against image 4. <strong>Result Analysis:</strong> Examine satisfied/violated regions</p>
<p><strong>Example Use Cases:</strong> - <strong>Lesion Detection:</strong> Find connected high-intensity regions - <strong>Anatomical Validation:</strong> Verify organ relationships - <strong>Quality Control:</strong> Check image acquisition artifacts</p>
<h3 id="voxlogica-vs.-traditional-methods">4.4 VoxLogica vs.&nbsp;Traditional Methods</h3>
<table class="caption-top">
<thead>
<tr class="header">
<th>Aspect</th>
<th>Traditional</th>
<th>VoxLogica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Specification</td>
<td>Procedural code</td>
<td>Declarative logic</td>
</tr>
<tr class="even">
<td>Verification</td>
<td>Testing</td>
<td>Formal proof</td>
</tr>
<tr class="odd">
<td>Interpretability</td>
<td>Code inspection</td>
<td>Logical reasoning</td>
</tr>
<tr class="even">
<td>Flexibility</td>
<td>High</td>
<td>Medium</td>
</tr>
<tr class="odd">
<td>Correctness</td>
<td>Empirical</td>
<td>Mathematical</td>
</tr>
</tbody>
</table>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="the-isola24-paper-towards-hybrid-ai-in-imaging-using-voxlogica-20-minutes" class="slide level2">
<h2>5. The ISOLA24 Paper: “Towards Hybrid-AI in Imaging Using VoxLogicA” (20 minutes)</h2>
<h3 id="paper-overview">5.1 Paper Overview</h3>
<p><strong>Publication Details:</strong> - <strong>Title:</strong> “Towards Hybrid-AI in Imaging Using VoxLogicA” - <strong>Authors:</strong> Gina Belmonte, Laura Bussi, Vincenzo Ciancia, Diego Latella, Mieke Massink - <strong>Venue:</strong> ISoLA 2024 (International Symposium on Leveraging Applications of Formal Methods) - <strong>Pages:</strong> 205-221 - <strong>DOI:</strong> 10.1007/978-3-031-75387-9_13</p>
<h3 id="research-context-and-significance">5.2 Research Context and Significance</h3>
<p><strong>ISOLA 2024 Focus:</strong> - Premier venue for bridging formal methods theory and practical applications - Emphasis on real-world impact of formal verification techniques - Platform for demonstrating innovative applications in critical domains</p>
<p><strong>Paper’s Contribution to Hybrid AI:</strong> This paper represents a significant step toward integrating formal methods with AI in medical imaging, addressing the critical need for: - <strong>Interpretable AI:</strong> Making AI decisions explainable to medical professionals - <strong>Reliable automation:</strong> Combining data-driven learning with domain knowledge - <strong>Clinical validation:</strong> Providing mathematical guarantees for medical applications</p>
<h3 id="key-research-contributions">5.3 Key Research Contributions</h3>
<p><strong>Methodological Advances:</strong> - <strong>Hybrid Architecture:</strong> Novel integration of VoxLogica spatial model checking with machine learning pipelines - <strong>Spatial Logic Extensions:</strong> New operators specifically designed for medical imaging applications - <strong>Performance Optimization:</strong> Efficient algorithms for real-time medical image analysis</p>
<p><strong>Practical Applications:</strong> - <strong>Medical Image Segmentation:</strong> Combining CNN-based segmentation with formal geometric constraints - <strong>Quality Assurance:</strong> Automated verification of imaging analysis results - <strong>Clinical Decision Support:</strong> Providing explainable reasoning for diagnostic assistance</p>
<h3 id="hybrid-ai-framework">5.4 Hybrid AI Framework</h3>
<p><strong>The VoxLogicA Approach:</strong> 1. <strong>ML Preprocessing:</strong> Neural networks handle noise reduction and initial feature extraction 2. <strong>Formal Specification:</strong> Spatial logic defines anatomical and pathological constraints 3. <strong>Model Checking:</strong> VoxLogicA verifies that ML results satisfy medical requirements 4. <strong>Hybrid Validation:</strong> Combined confidence from both statistical and logical reasoning</p>
<p><strong>Example Workflow:</strong></p>
<pre><code>Medical Image → CNN Segmentation → VoxLogicA Verification → Validated Results
                     ↓                        ↓
              Statistical Confidence    Logical Certainty
                     ↓                        ↓
                    Combined Hybrid Confidence Score</code></pre>
<h3 id="clinical-impact-and-future-directions">5.5 Clinical Impact and Future Directions</h3>
<p><strong>Immediate Benefits:</strong> - <strong>Increased Trust:</strong> Medical professionals can understand and verify AI decisions - <strong>Reduced Errors:</strong> Formal constraints catch ML mistakes that violate medical knowledge - <strong>Regulatory Compliance:</strong> Mathematical verification supports medical device approval</p>
<p><strong>Future Research Directions:</strong> - <strong>Scalability:</strong> Extending to larger, more complex medical imaging datasets - <strong>Real-time Processing:</strong> Optimizing for clinical workflow integration - <strong>Multi-modal Integration:</strong> Combining different imaging modalities with unified formal specifications</p>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="recent-advances-medical-imaging-applications-15-minutes" class="slide level2">
<h2>6. Recent Advances: Medical Imaging Applications (15 minutes)</h2>
<h3 id="contemporary-research-in-medical-imaging">6.1 Contemporary Research in Medical Imaging</h3>
<p><strong>Recent Work by Course Instructor:</strong> Building on the theoretical foundations established in previous work, recent research has focused on practical applications of formal methods in clinical medical imaging scenarios.</p>
<p><strong>Key Research Areas:</strong> - <strong>Clinical Validation:</strong> Real-world testing of VoxLogica in hospital environments - <strong>Multi-modal Integration:</strong> Combining MRI, CT, and ultrasound data analysis - <strong>Performance Optimization:</strong> Scaling formal methods for large medical datasets - <strong>Regulatory Compliance:</strong> Meeting FDA and CE marking requirements for medical AI</p>
<h3 id="practical-applications-in-medicine">6.2 Practical Applications in Medicine</h3>
<p><strong>Current Medical Imaging Challenges:</strong> - <strong>Diagnostic Accuracy:</strong> Reducing false positives and negatives in automated analysis - <strong>Workflow Integration:</strong> Seamlessly incorporating AI tools into clinical practice - <strong>Interpretability Requirements:</strong> Meeting regulatory demands for explainable AI - <strong>Multi-institutional Validation:</strong> Ensuring methods work across different hospitals and equipment</p>
<p><strong>Formal Methods Solutions:</strong> - <strong>Spatial Logic Specifications:</strong> Encoding medical knowledge as verifiable constraints - <strong>Hybrid Validation:</strong> Combining statistical and logical confidence measures - <strong>Quality Assurance:</strong> Automated detection of analysis errors and artifacts - <strong>Documentation:</strong> Providing audit trails for regulatory compliance</p>
<h3 id="impact-on-medical-practice">6.3 Impact on Medical Practice</h3>
<p><strong>Clinical Benefits:</strong> - <strong>Enhanced Diagnostic Confidence:</strong> Doctors can verify AI reasoning - <strong>Reduced Training Time:</strong> Formal specifications capture expert knowledge - <strong>Standardization:</strong> Consistent analysis across different institutions - <strong>Risk Mitigation:</strong> Mathematical guarantees reduce liability concerns</p>
<p><strong>Research Contributions:</strong> - <strong>Methodological Advances:</strong> New spatial operators for medical imaging - <strong>Performance Studies:</strong> Comparative analysis of hybrid vs.&nbsp;pure ML approaches - <strong>Clinical Validation:</strong> Real-world testing in medical environments - <strong>Tool Development:</strong> User-friendly interfaces for medical professionals</p>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="ethics-and-human-centric-ai-in-medical-imaging-20-minutes" class="slide level2">
<h2>7. Ethics and Human-Centric AI in Medical Imaging (20 minutes)</h2>
<h3 id="ethical-considerations">6.1 Ethical Considerations</h3>
<p><strong>Key Principles:</strong> - <strong>Transparency:</strong> AI decisions must be explainable to medical professionals - <strong>Accountability:</strong> Clear responsibility for AI-assisted diagnoses - <strong>Fairness:</strong> Avoiding bias in training data and algorithms - <strong>Privacy:</strong> Protecting patient data and medical information</p>
<h3 id="the-human-centric-approach">6.2 The Human-Centric Approach</h3>
<p><strong>Human-in-the-Loop:</strong> - AI assists but doesn’t replace medical expertise - Doctors maintain final decision authority - Continuous feedback improves system performance</p>
<p><strong>Hybrid AI Benefits:</strong> - <strong>Interpretability:</strong> Formal methods provide clear reasoning - <strong>Validation:</strong> Multiple approaches increase confidence - <strong>Flexibility:</strong> Adapts to different clinical workflows - <strong>Trust:</strong> Transparent processes build user confidence</p>
<h3 id="regulatory-and-professional-considerations">6.3 Regulatory and Professional Considerations</h3>
<p><strong>Medical Device Regulation:</strong> - AI systems must meet safety and efficacy standards - Formal verification can support regulatory approval - Documentation and traceability requirements</p>
<p><strong>Professional Standards:</strong> - Integration with existing clinical workflows - Training requirements for medical professionals - Quality assurance and continuous monitoring</p>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="course-preview-and-next-steps-10-minutes" class="slide level2">
<h2>8. Course Preview and Next Steps (10 minutes)</h2>
<h3 id="course-journey">7.1 Course Journey</h3>
<p><strong>Weeks 1-4:</strong> Foundations - Image generation and preprocessing - Traditional image processing - Programming with ITK/SimpleITK</p>
<p><strong>Weeks 5-8:</strong> Formal Methods - Deep dive into VoxLogica - Spatial logic programming - Case studies and applications</p>
<p><strong>Weeks 9-12:</strong> Hybrid Approaches - Machine learning integration - Performance evaluation - Real-world applications</p>
<h3 id="learning-approach">7.2 Learning Approach</h3>
<p><strong>Theory + Practice:</strong> - Conceptual understanding of methods - Hands-on programming exercises - Real medical imaging datasets</p>
<p><strong>Progressive Complexity:</strong> - Start with basic concepts - Build to sophisticated hybrid systems - Culminate in individual projects</p>
</section>
<section class="slide level2">

<!-- Transition: Moving to next topic -->
</section>
<section id="summary-and-key-takeaways" class="slide level2">
<h2>Summary and Key Takeaways</h2>
<ol type="1">
<li><strong>Hybrid AI</strong> combines symbolic and subsymbolic approaches for robust medical imaging solutions</li>
<li><strong>Formal methods</strong> provide mathematical precision and verification capabilities</li>
<li><strong>VoxLogica</strong> enables declarative specification of spatial properties in medical images</li>
<li><strong>Ethics and transparency</strong> are crucial in medical AI applications</li>
<li><strong>Integration</strong> of multiple approaches addresses individual method limitations</li>
</ol>
</section>
<section id="preparation-for-next-lecture" class="slide level2">
<h2>Preparation for Next Lecture</h2>
<p><strong>Reading:</strong> - Review basic concepts of medical imaging modalities - Familiarize yourself with Python programming basics - Install required software (instructions will be provided)</p>
<p><strong>Questions to Consider:</strong> - How might formal verification improve trust in medical AI? - What spatial relationships are important in your area of medical interest? - How can we balance automation with human expertise in medical imaging?</p>
</section>
<section id="references-and-further-reading" class="slide level2">
<h2>References and Further Reading</h2>
<ol type="1">
<li><p><strong>Belmonte, G., Bussi, L., Ciancia, V., Latella, D., Massink, M.</strong> (2024). “Towards Hybrid-AI in Imaging Using VoxLogicA.” <em>ISoLA 2024: Leveraging Applications of Formal Methods</em>, pp.&nbsp;205-221. DOI: 10.1007/978-3-031-75387-9_13</p></li>
<li><p><strong>Ciancia, V., et al.</strong> (2024). “[Recent Medical Imaging Paper Title].” <em>[Medical Imaging Journal]</em>, [Volume], [Pages]. DOI: [DOI] <em>Note: Please update with specific details of your recent medical imaging publication</em></p></li>
</ol>
</section>
<section id="references-and-further-reading-2" class="slide level2">
<h2>References and Further Reading (2)</h2>
<ol start="3" type="1">
<li><p><strong>Ciancia, V., Latella, D., Loreti, M., Massink, M.</strong> (2014). “Specifying and verifying properties of space.” <em>Theoretical Computer Science</em>, 550, 25-41.</p></li>
<li><p><strong>Nenzi, L., Bortolussi, L., Ciancia, V., Loreti, M., Massink, M.</strong> (2015). “Qualitative and quantitative monitoring of spatio-temporal properties.” <em>Runtime Verification</em>, pp.&nbsp;21-37.</p></li>
<li><p><strong>Bartocci, E., Bortolussi, L., Loreti, M., Nenzi, L.</strong> (2018). “Monitoring mobile and spatially distributed cyber-physical systems.” <em>ACM Computing Surveys</em>, 51(4), 1-29.</p></li>
</ol>
</section>
<section id="references-and-further-reading-3" class="slide level2">
<h2>References and Further Reading (3)</h2>
<ol start="5" type="1">
<li><p><strong>Medical Imaging Ethics Guidelines:</strong> IEEE Standards for Medical Device Software, FDA Guidelines for AI/ML-Based Medical Devices</p></li>
<li><p><strong>VoxLogicA Tool and Documentation:</strong> Available at the official VoxLogicA repository and ISTI-CNR research pages</p></li>
<li><p><strong>Recent Advances in Hybrid AI:</strong> Survey papers on neuro-symbolic AI and explainable AI in healthcare applications</p></li>
</ol>

</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="A_Lecture_notes_slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>