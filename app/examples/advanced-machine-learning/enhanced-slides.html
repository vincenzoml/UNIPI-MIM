<!DOCTYPE html>
<html lang="en"><head>
<script src="enhanced-slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="enhanced-slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="enhanced-slides_files/libs/quarto-html/popper.min.js"></script>
<script src="enhanced-slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="enhanced-slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="enhanced-slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="enhanced-slides_files/libs/quarto-html/quarto-syntax-highlighting-dark-748b535e376f14d4692bf2b2e5fd6380.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.29">

  <meta name="author" content="Prof.&nbsp;AI Researcher">
  <meta name="dcterms.date" content="2025-01-01">
  <title>Advanced Machine Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="enhanced-slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="enhanced-slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #f8f8f2;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #f8f8f2; } /* Normal */
    code span.al { color: #f07178; } /* Alert */
    code span.an { color: #d4d0ab; } /* Annotation */
    code span.at { color: #00e0e0; } /* Attribute */
    code span.bn { color: #d4d0ab; } /* BaseN */
    code span.bu { color: #abe338; } /* BuiltIn */
    code span.cf { color: #ffa07a; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #abe338; } /* Char */
    code span.cn { color: #ffd700; } /* Constant */
    code span.co { color: #f8f8f2; font-style: italic; } /* Comment */
    code span.cv { color: #ffd700; } /* CommentVar */
    code span.do { color: #f8f8f2; } /* Documentation */
    code span.dt { color: #ffa07a; } /* DataType */
    code span.dv { color: #d4d0ab; } /* DecVal */
    code span.er { color: #f07178; text-decoration: underline; } /* Error */
    code span.ex { color: #00e0e0; font-weight: bold; } /* Extension */
    code span.fl { color: #d4d0ab; } /* Float */
    code span.fu { color: #ffa07a; } /* Function */
    code span.im { color: #abe338; } /* Import */
    code span.in { color: #d4d0ab; } /* Information */
    code span.kw { color: #ffa07a; font-weight: bold; } /* Keyword */
    code span.op { color: #ffa07a; } /* Operator */
    code span.ot { color: #00e0e0; } /* Other */
    code span.pp { color: #dcc6e0; } /* Preprocessor */
    code span.re { color: #00e0e0; background-color: #f8f8f2; } /* RegionMarker */
    code span.sc { color: #abe338; } /* SpecialChar */
    code span.ss { color: #abe338; } /* SpecialString */
    code span.st { color: #abe338; } /* String */
    code span.va { color: #00e0e0; } /* Variable */
    code span.vs { color: #abe338; } /* VerbatimString */
    code span.wa { color: #dcc6e0; } /* Warning */
  </style>
  <link rel="stylesheet" href="enhanced-slides_files/libs/revealjs/dist/theme/quarto-0c8acc74dca0c2faaedea4940f202713.css">
  <link rel="stylesheet" href="enhanced-dark.css">
  <link href="enhanced-slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="enhanced-slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="enhanced-slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="enhanced-slides_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="enhanced-slides_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="enhanced-slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Advanced Machine Learning</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Prof.&nbsp;AI Researcher 
</div>
        <p class="quarto-title-affiliation">
            University of Pisa
          </p>
    </div>
</div>

  <p class="date">2025-01-01</p>
</section>
<section>
<section id="advanced-machine-learning-deep-neural-networks" class="title-slide slide level1 center">
<h1>Advanced Machine Learning: Deep Neural Networks</h1>
<p><strong>Author</strong>: Prof.&nbsp;AI Researcher<br>
<strong>Date</strong>: September 2025<br>
<strong>Institute</strong>: University of Pisa - Master in AI</p>
<!-- SLIDE -->
</section>
<section id="overview" class="slide level2 center">
<h2>Overview</h2>
<p>Today we’ll explore the cutting-edge world of deep neural networks, covering:</p>
<ul>
<li>Mathematical foundations of deep learning</li>
<li>Advanced architectures and their applications</li>
<li>Optimization techniques and regularization</li>
<li>Practical implementation strategies</li>
</ul>
<!-- NOTES-ONLY -->
<p>This lecture builds on previous knowledge of basic machine learning concepts. Students should be familiar with linear algebra, calculus, and probability theory. We’ll dive deep into the theoretical foundations while maintaining practical relevance through real-world examples.</p>
<p>The lecture is structured to progressively build complexity, starting from fundamental concepts and moving toward state-of-the-art techniques used in modern AI research.</p>
<!-- SLIDE -->
</section>
<section id="the-universal-approximation-theorem" class="slide level2 center">
<h2>The Universal Approximation Theorem</h2>
<p>Neural networks are <strong>universal function approximators</strong>:</p>
<p><span class="math display">\[f(x) = \sum_{i=1}^{n} w_i \sigma(W_i^T x + b_i)\]</span></p>
<p>Where: - <span class="math inline">\(\sigma\)</span> is the activation function - <span class="math inline">\(W_i\)</span> are weight matrices<br>
- <span class="math inline">\(b_i\)</span> are bias vectors - <span class="math inline">\(n\)</span> is the number of hidden units</p>
<!-- NOTES-ONLY -->
<p>The Universal Approximation Theorem, first proven by Cybenko in 1989, states that a feedforward network with a single hidden layer containing a finite number of neurons can approximate any continuous function on compact subsets of <span class="math inline">\(\mathbb{R}^n\)</span> to arbitrary accuracy.</p>
<p>This is a profound theoretical result that provides the mathematical foundation for why neural networks work. However, the theorem doesn’t tell us: 1. How many neurons we need 2. How to find the optimal weights 3. Whether the approximation generalizes to unseen data</p>
<p>In practice, deeper networks often achieve better performance with fewer parameters than very wide shallow networks.</p>
<!-- ALL -->

<!-- SLIDE -->
<img data-src="figures/neural_network.svg" class="r-stretch quarto-figure-center"><p class="caption">Neural Network Architecture</p></section>
<section id="deep-learning-mathematics" class="slide level2 center">
<h2>Deep Learning Mathematics</h2>
<h3 id="gradient-computation-via-backpropagation">Gradient Computation via Backpropagation</h3>
<p>The chain rule enables efficient gradient computation:</p>
<p><span class="math display">\[\frac{\partial L}{\partial W^{(l)}} = \frac{\partial L}{\partial z^{(l+1)}} \cdot \frac{\partial z^{(l+1)}}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial W^{(l)}}\]</span></p>
<h3 id="loss-function-landscape">Loss Function Landscape</h3>
<p>For classification with <span class="math inline">\(C\)</span> classes:</p>
<p><span class="math display">\[L_{CE} = -\sum_{i=1}^{N} \sum_{c=1}^{C} y_{ic} \log(\hat{y}_{ic})\]</span></p>
<!-- NOTES-ONLY -->
<p>Backpropagation is the heart of neural network training. The algorithm efficiently computes gradients by applying the chain rule recursively from the output layer back to the input layer.</p>
<p>Key insights about the gradient computation:</p>
<ol type="1">
<li><p><strong>Computational Graph</strong>: We can represent the forward pass as a computational graph where each node represents an operation.</p></li>
<li><p><strong>Dynamic Programming</strong>: Backpropagation is essentially dynamic programming applied to gradient computation, avoiding redundant calculations.</p></li>
<li><p><strong>Vanishing Gradients</strong>: In very deep networks, gradients can become exponentially small, making training difficult. This led to innovations like:</p>
<ul>
<li>Skip connections (ResNet)</li>
<li>Better activation functions (ReLU, Swish)</li>
<li>Normalization techniques (BatchNorm, LayerNorm)</li>
</ul></li>
<li><p><strong>Exploding Gradients</strong>: Conversely, gradients can also explode, leading to unstable training. Gradient clipping is a common solution.</p></li>
</ol>
<p>The cross-entropy loss function is particularly well-suited for classification because: - It’s convex in the final layer weights - It provides strong gradients when predictions are confident but wrong - It naturally handles the probabilistic interpretation of softmax outputs</p>
<!-- SLIDE -->
</section>
<section id="advanced-architectures" class="slide level2 center">
<h2>Advanced Architectures</h2>
<h3 id="convolutional-neural-networks-cnns">Convolutional Neural Networks (CNNs)</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="co"># Modern CNN block with residual connections</span></span>
<span id="cb1-2"><a href=""></a><span class="kw">class</span> ResidualBlock(nn.Module):</span>
<span id="cb1-3"><a href=""></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels):</span>
<span id="cb1-4"><a href=""></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-5"><a href=""></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(channels, channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-6"><a href=""></a>        <span class="va">self</span>.bn1 <span class="op">=</span> nn.BatchNorm2d(channels)</span>
<span id="cb1-7"><a href=""></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(channels, channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-8"><a href=""></a>        <span class="va">self</span>.bn2 <span class="op">=</span> nn.BatchNorm2d(channels)</span>
<span id="cb1-9"><a href=""></a>        <span class="va">self</span>.relu <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-10"><a href=""></a>        </span>
<span id="cb1-11"><a href=""></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-12"><a href=""></a>        identity <span class="op">=</span> x</span>
<span id="cb1-13"><a href=""></a>        out <span class="op">=</span> <span class="va">self</span>.relu(<span class="va">self</span>.bn1(<span class="va">self</span>.conv1(x)))</span>
<span id="cb1-14"><a href=""></a>        out <span class="op">=</span> <span class="va">self</span>.bn2(<span class="va">self</span>.conv2(out))</span>
<span id="cb1-15"><a href=""></a>        out <span class="op">+=</span> identity  <span class="co"># Skip connection</span></span>
<span id="cb1-16"><a href=""></a>        <span class="cf">return</span> <span class="va">self</span>.relu(out)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- SLIDE -->
<h3 id="attention-mechanisms">Attention Mechanisms</h3>
<p>The attention weight computation:</p>
<p><span class="math display">\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\]</span></p>
<p>Where: - <span class="math inline">\(Q\)</span> is the query matrix - <span class="math inline">\(K\)</span> is the key matrix<br>
- <span class="math inline">\(V\)</span> is the value matrix - <span class="math inline">\(d_k\)</span> is the key dimension</p>
<!-- NOTES-ONLY -->
<p>Attention mechanisms have revolutionized deep learning, particularly in natural language processing and computer vision. The key insight is that not all parts of the input are equally important for making predictions.</p>
<p><strong>Self-Attention</strong>: When Q, K, and V all come from the same input sequence, we get self-attention. This allows the model to relate different positions in the sequence to each other.</p>
<p><strong>Multi-Head Attention</strong>: Instead of using a single attention function, we can use multiple attention “heads”:</p>
<p><span class="math display">\[\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O\]</span></p>
<p>where <span class="math inline">\(\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\)</span></p>
<p>This allows the model to attend to information from different representation subspaces at different positions simultaneously.</p>
<p><strong>Computational Complexity</strong>: The attention mechanism has <span class="math inline">\(O(n^2)\)</span> complexity with respect to sequence length, which can be prohibitive for very long sequences. Recent innovations like: - Sparse attention patterns - Linear attention - Efficient attention approximations</p>
<p>aim to address this limitation.</p>
<!-- SLIDE -->
</section>
<section id="training-dynamics-optimization" class="slide level2 center">
<h2>Training Dynamics &amp; Optimization</h2>
<h3 id="adaptive-learning-rates">Adaptive Learning Rates</h3>
<p>Adam optimizer combines momentum and adaptive learning rates:</p>
<p><span class="math display">\[m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t\]</span> <span class="math display">\[v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2\]</span> <span class="math display">\[\hat{m}_t = \frac{m_t}{1-\beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1-\beta_2^t}\]</span> <span class="math display">\[\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon}\hat{m}_t\]</span></p>
<!-- ALL -->

<!-- SLIDE -->
<img data-src="figures/loss_function.png" class="r-stretch quarto-figure-center"><p class="caption">Training Loss Curve</p><h3 id="regularization-techniques">Regularization Techniques</h3>
<p><strong>Dropout</strong>: Randomly zero out neurons during training</p>
<p><strong>Batch Normalization</strong>: Normalize layer inputs</p>
<p><span class="math display">\[\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}\]</span> <span class="math display">\[y = \gamma \hat{x} + \beta\]</span></p>
<p><strong>Weight Decay</strong>: L2 regularization on parameters</p>
<p><span class="math display">\[L_{total} = L_{data} + \lambda \sum_i w_i^2\]</span></p>
<!-- NOTES-ONLY -->
<p>Regularization is crucial for preventing overfitting in deep networks. Let’s examine each technique:</p>
<p><strong>Dropout</strong> (Srivastava et al., 2014): - During training, randomly set activations to zero with probability <span class="math inline">\(p\)</span> - Forces the network to not rely on specific neurons - Equivalent to training an ensemble of networks - At test time, scale activations by <span class="math inline">\((1-p)\)</span> or use “inverted dropout”</p>
<p><strong>Batch Normalization</strong> (Ioffe &amp; Szegedy, 2015): - Normalizes inputs to each layer to have zero mean and unit variance - Reduces internal covariate shift - Allows higher learning rates - Acts as a regularizer (slight noise from batch statistics) - <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span> are learnable parameters that allow the network to undo the normalization if needed</p>
<p><strong>Weight Decay</strong>: - Penalizes large weights, encouraging simpler models - Equivalent to L2 regularization when using SGD - Note: With Adam optimizer, weight decay and L2 regularization are different!</p>
<p><strong>Other Modern Techniques</strong>: - <strong>Layer Normalization</strong>: Normalizes across features instead of batch - <strong>Group Normalization</strong>: Compromise between batch and layer norm - <strong>Spectral Normalization</strong>: Controls Lipschitz constant of layers</p>
<!-- SLIDE -->
</section>
<section id="practical-implementation" class="slide level2 center">
<h2>Practical Implementation</h2>
<h3 id="data-pipeline-optimization">Data Pipeline Optimization</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="co"># Efficient data loading with PyTorch</span></span>
<span id="cb2-2"><a href=""></a><span class="kw">class</span> ImageDataset(Dataset):</span>
<span id="cb2-3"><a href=""></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_paths, transforms<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-4"><a href=""></a>        <span class="va">self</span>.image_paths <span class="op">=</span> image_paths</span>
<span id="cb2-5"><a href=""></a>        <span class="va">self</span>.transforms <span class="op">=</span> transforms</span>
<span id="cb2-6"><a href=""></a>        </span>
<span id="cb2-7"><a href=""></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb2-8"><a href=""></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(<span class="va">self</span>.image_paths[idx])</span>
<span id="cb2-9"><a href=""></a>        <span class="cf">if</span> <span class="va">self</span>.transforms:</span>
<span id="cb2-10"><a href=""></a>            image <span class="op">=</span> <span class="va">self</span>.transforms(image)</span>
<span id="cb2-11"><a href=""></a>        <span class="cf">return</span> image</span>
<span id="cb2-12"><a href=""></a>        </span>
<span id="cb2-13"><a href=""></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb2-14"><a href=""></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.image_paths)</span>
<span id="cb2-15"><a href=""></a></span>
<span id="cb2-16"><a href=""></a><span class="co"># Multi-worker data loading</span></span>
<span id="cb2-17"><a href=""></a>dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb2-18"><a href=""></a>    dataset, </span>
<span id="cb2-19"><a href=""></a>    batch_size<span class="op">=</span><span class="dv">32</span>, </span>
<span id="cb2-20"><a href=""></a>    num_workers<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb2-21"><a href=""></a>    pin_memory<span class="op">=</span><span class="va">True</span>  <span class="co"># Faster GPU transfer</span></span>
<span id="cb2-22"><a href=""></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- SLIDE -->
<h3 id="model-evaluation-metrics">Model Evaluation Metrics</h3>
<p>For classification tasks, we track multiple metrics:</p>
<p><strong>Accuracy</strong>: <span class="math inline">\(\frac{\text{Correct Predictions}}{\text{Total Predictions}}\)</span></p>
<p><strong>Precision</strong>: <span class="math inline">\(\frac{TP}{TP + FP}\)</span></p>
<p><strong>Recall</strong>: <span class="math inline">\(\frac{TP}{TP + FN}\)</span></p>
<p><strong>F1-Score</strong>: <span class="math inline">\(\frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}\)</span></p>
<!-- ALL -->

<!-- SLIDE -->
<img data-src="figures/confusion_matrix.png" class="r-stretch quarto-figure-center"><p class="caption">Confusion Matrix</p></section>
<section id="cutting-edge-research-directions" class="slide level2 center">
<h2>Cutting-Edge Research Directions</h2>
<h3 id="self-supervised-learning">Self-Supervised Learning</h3>
<p>Learning representations without labels:</p>
<ul>
<li><strong>Contrastive Learning</strong>: SimCLR, MoCo, SwAV</li>
<li><strong>Masked Language Modeling</strong>: BERT, RoBERTa</li>
<li><strong>Autoregressive Generation</strong>: GPT, PaLM</li>
</ul>
<h3 id="neural-architecture-search-nas">Neural Architecture Search (NAS)</h3>
<p>Automating architecture design:</p>
<p><span class="math display">\[\mathcal{A}^* = \arg\max_{\mathcal{A} \in \mathcal{S}} \text{Accuracy}(\mathcal{A}) - \lambda \cdot \text{Complexity}(\mathcal{A})\]</span></p>
<!-- NOTES-ONLY -->
<p>The field is rapidly evolving with several exciting research directions:</p>
<p><strong>Self-Supervised Learning</strong>: This paradigm aims to learn useful representations from unlabeled data by designing pretext tasks. Key approaches include:</p>
<ol type="1">
<li><strong>Contrastive Methods</strong>: Learn by pulling similar examples together and pushing dissimilar ones apart
<ul>
<li>SimCLR: Uses data augmentation to create positive pairs</li>
<li>MoCo: Maintains a queue of negative examples</li>
<li>SwAV: Uses cluster assignments as targets</li>
</ul></li>
<li><strong>Generative Methods</strong>: Learn by reconstructing input data
<ul>
<li>Masked language modeling (BERT)</li>
<li>Autoregressive generation (GPT)</li>
<li>Masked autoencoders (MAE)</li>
</ul></li>
</ol>
<p><strong>Neural Architecture Search</strong>: - <strong>Differentiable NAS</strong>: DARTS makes architecture search differentiable - <strong>Efficient Search</strong>: Progressive search, early stopping, weight sharing - <strong>Hardware-Aware NAS</strong>: Optimize for specific deployment constraints</p>
<p><strong>Emerging Paradigms</strong>: - <strong>Foundation Models</strong>: Large-scale pre-trained models (GPT, CLIP) - <strong>Few-Shot Learning</strong>: Learning from minimal examples - <strong>Continual Learning</strong>: Learning new tasks without forgetting old ones - <strong>Federated Learning</strong>: Training across distributed devices while preserving privacy</p>
<!-- SLIDE -->
</section>
<section id="hands-on-exercise" class="slide level2 center">
<h2>Hands-On Exercise</h2>
<h3 id="building-a-modern-cnn">Building a Modern CNN</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href=""></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href=""></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-3"><a href=""></a></span>
<span id="cb3-4"><a href=""></a><span class="kw">class</span> ModernCNN(nn.Module):</span>
<span id="cb3-5"><a href=""></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb3-6"><a href=""></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-7"><a href=""></a>        </span>
<span id="cb3-8"><a href=""></a>        <span class="co"># Feature extraction</span></span>
<span id="cb3-9"><a href=""></a>        <span class="va">self</span>.features <span class="op">=</span> nn.Sequential(</span>
<span id="cb3-10"><a href=""></a>            <span class="co"># Block 1</span></span>
<span id="cb3-11"><a href=""></a>            nn.Conv2d(<span class="dv">3</span>, <span class="dv">64</span>, <span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>),</span>
<span id="cb3-12"><a href=""></a>            nn.BatchNorm2d(<span class="dv">64</span>),</span>
<span id="cb3-13"><a href=""></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb3-14"><a href=""></a>            nn.MaxPool2d(<span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb3-15"><a href=""></a>            </span>
<span id="cb3-16"><a href=""></a>            <span class="co"># Block 2 - Residual blocks would go here</span></span>
<span id="cb3-17"><a href=""></a>            <span class="va">self</span>._make_layer(<span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">2</span>),</span>
<span id="cb3-18"><a href=""></a>            <span class="va">self</span>._make_layer(<span class="dv">128</span>, <span class="dv">256</span>, <span class="dv">2</span>),</span>
<span id="cb3-19"><a href=""></a>            <span class="va">self</span>._make_layer(<span class="dv">256</span>, <span class="dv">512</span>, <span class="dv">2</span>),</span>
<span id="cb3-20"><a href=""></a>        )</span>
<span id="cb3-21"><a href=""></a>        </span>
<span id="cb3-22"><a href=""></a>        <span class="co"># Classification head</span></span>
<span id="cb3-23"><a href=""></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb3-24"><a href=""></a>            nn.AdaptiveAvgPool2d((<span class="dv">1</span>, <span class="dv">1</span>)),</span>
<span id="cb3-25"><a href=""></a>            nn.Flatten(),</span>
<span id="cb3-26"><a href=""></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb3-27"><a href=""></a>            nn.Linear(<span class="dv">512</span>, num_classes)</span>
<span id="cb3-28"><a href=""></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- SLIDE-ONLY -->
<h3 id="training-loop-template">Training Loop Template</h3>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a><span class="kw">def</span> train_epoch(model, dataloader, optimizer, criterion):</span>
<span id="cb4-2"><a href=""></a>    model.train()</span>
<span id="cb4-3"><a href=""></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-4"><a href=""></a>    </span>
<span id="cb4-5"><a href=""></a>    <span class="cf">for</span> batch_idx, (data, target) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb4-6"><a href=""></a>        optimizer.zero_grad()</span>
<span id="cb4-7"><a href=""></a>        output <span class="op">=</span> model(data)</span>
<span id="cb4-8"><a href=""></a>        loss <span class="op">=</span> criterion(output, target)</span>
<span id="cb4-9"><a href=""></a>        loss.backward()</span>
<span id="cb4-10"><a href=""></a>        optimizer.step()</span>
<span id="cb4-11"><a href=""></a>        </span>
<span id="cb4-12"><a href=""></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb4-13"><a href=""></a>        </span>
<span id="cb4-14"><a href=""></a>        <span class="cf">if</span> batch_idx <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb4-15"><a href=""></a>            <span class="bu">print</span>(<span class="ss">f'Batch </span><span class="sc">{</span>batch_idx<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb4-16"><a href=""></a>    </span>
<span id="cb4-17"><a href=""></a>    <span class="cf">return</span> total_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- SLIDE -->
</section>
<section id="key-takeaways" class="slide level2 center">
<h2>Key Takeaways</h2>
<h3 id="theoretical-insights">Theoretical Insights</h3>
<ol type="1">
<li><strong>Universal Approximation</strong>: Neural networks can approximate any function</li>
<li><strong>Optimization Landscape</strong>: Non-convex but practically trainable</li>
<li><strong>Generalization</strong>: Capacity control through regularization</li>
</ol>
<h3 id="practical-guidelines">Practical Guidelines</h3>
<ol type="1">
<li><strong>Start Simple</strong>: Begin with standard architectures</li>
<li><strong>Data First</strong>: Quality data &gt; complex models</li>
<li><strong>Iterate Fast</strong>: Rapid prototyping and experimentation</li>
<li><strong>Monitor Everything</strong>: Loss, gradients, activations</li>
</ol>
<!-- NOTES-ONLY -->
<p>As we conclude this advanced lecture on deep neural networks, let’s consolidate the key insights:</p>
<p><strong>Theoretical Foundation</strong>: - The universal approximation theorem provides the mathematical foundation for neural networks - Backpropagation enables efficient gradient computation through the chain rule - Understanding the loss landscape helps us navigate optimization challenges</p>
<p><strong>Architectural Evolution</strong>: - From simple MLPs to complex architectures like ResNets and Transformers - Each architectural innovation addresses specific limitations of previous approaches - Attention mechanisms have become ubiquitous across domains</p>
<p><strong>Training Considerations</strong>: - Modern optimizers like Adam adapt learning rates automatically - Regularization techniques prevent overfitting and improve generalization - Proper initialization and normalization are crucial for training stability</p>
<p><strong>Current Research</strong>: - Self-supervised learning reduces dependence on labeled data - Neural architecture search automates design decisions - Foundation models are changing how we think about AI deployment</p>
<p><strong>Practical Wisdom</strong>: - Start with proven architectures and adapt gradually - Invest time in understanding your data and problem domain - Monitor training dynamics carefully - they tell you what’s happening - Don’t optimize prematurely - get a working baseline first</p>
<p>The field of deep learning continues to evolve rapidly. Stay curious, experiment boldly, but always ground your work in solid fundamentals.</p>
<!-- ALL -->
</section>
<section id="references-further-reading" class="slide level2 center">
<h2>References &amp; Further Reading</h2>
<ol type="1">
<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</li>
<li>He, K., et al.&nbsp;(2016). Deep Residual Learning for Image Recognition. CVPR.</li>
<li>Vaswani, A., et al.&nbsp;(2017). Attention is All You Need. NeurIPS.</li>
<li>Kingma, D. P., &amp; Ba, J. (2015). Adam: A Method for Stochastic Optimization. ICLR.</li>
</ol>
</section>
<section class="slide level2 center">

<p><em>Next lecture: Advanced Topics in Generative Models</em></p>

</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Advanced Machine Learning • University of Pisa • Fall 2025</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="enhanced-slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="enhanced-slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="enhanced-slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="enhanced-slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: true,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'convex',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 720,

        // Factor of the display size that should remain empty around the content
        margin: 4.0e-2,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.2,

        maxScale: 2,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
                // target, if specified
                link.setAttribute("target", "_blank");
                if (link.getAttribute("rel") === null) {
                  link.setAttribute("rel", "noopener");
                }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>